---
title: "Learning multimodal representations for sample-efficient recognition of human actions"
date: 2019-01-01
publishDate: 2020-01-04T22:12:20.063067Z
authors: ["**Miguel Vasco**", "Francisco S. Melo", "David Martins de Matos", "Ana Paiva", "Tetsunari Inamura"]
publication_types: ["1"]
abstract: "Humans interact in rich and diverse ways with the environment. However,  the representation of such behavior by artificial agents is often limited. In this work we present textitmotion concepts, a novel multimodal representation of human actions in a household environment. A motion concept encompasses a probabilistic description of the kinematics of the action along with its contextual background, namely the location and the objects held during the performance. Furthermore, we present Online Motion Concept Learning (OMCL), a new algorithm which learns novel motion concepts from action demonstrations and recognizes previously learned motion concepts. The algorithm is evaluated on a virtual-reality household environment with the presence of a human avatar. OMCL outperforms standard motion recognition algorithms on an one-shot recognition task, attesting to its potential for sample-efficient recognition of human actions."
featured: true
publication: ""
tags: ["Computer Science - Artificial Intelligence", "Computer Science - Computer Vision and Pattern Recognition", "Computer Science - Machine Learning"]
url_pdf: "https://arxiv.org/abs/1903.02511"

image:
  placement: 1
  caption: ''
  focal_point: "Top"
  preview_only: false


---
