@inproceedings{vasco_learning_2019,
 abstract = {Humans interact in rich and diverse ways with the environment. However, 
the representation of such behavior by artificial agents is often
limited. In this work we present \textit\motion concepts\, a novel
multimodal representation of human actions in a household environment. A
motion concept encompasses a probabilistic description of the kinematics
of the action along with its contextual background, namely the location
and the objects held during the performance. Furthermore, we present
Online Motion Concept Learning (OMCL), a new algorithm which learns
novel motion concepts from action demonstrations and recognizes
previously learned motion concepts. The algorithm is evaluated on a
virtual-reality household environment with the presence of a human
avatar. OMCL outperforms standard motion recognition algorithms on an
one-shot recognition task, attesting to its potential for
sample-efficient recognition of human actions.},
 address = {Macau, China},
 author = {Vasco, Miguel and Melo, Francisco S. and Martins de Matos, David and Paiva, Ana and Inamura, Tetsunari},
 file = {Full Text PDF:/Users/miguelvasco/Zotero/storage/57YWHM9L/Vasco et al. - 2019 - Learning multimodal representations for sample-eff.pdf:application/pdf},
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
 title = {Learning multimodal representations for sample-efficient recognition of human actions},
 urldate = {2020-01-04},
 year = {2019}
}

