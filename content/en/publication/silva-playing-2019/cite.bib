@article{silva_playing_2019,
 abstract = {In this work we explore the use of latent representations obtained from multiple input sensory modalities (such as images or sounds) in allowing an agent to learn and exploit policies over different subsets of input modalities. We propose a three-stage architecture that allows a reinforcement learning agent trained over a given sensory modality, to execute its task on a different sensory modality-for example, learning a visual policy over image inputs, and then execute such policy when only sound inputs are available. We show that the generalized policies achieve better out-of-the-box performance when compared to different baselines. Moreover, we show this holds in different OpenAI gym and video game environments, even when using different multimodal generative models and reinforcement learning algorithms.},
 author = {Silva, Rui and Vasco, Miguel and Melo, Francisco S. and Paiva, Ana and Veloso, Manuela},
 copyright = {All rights reserved},
 file = {arXiv Fulltext PDF:/Users/miguelvasco/Zotero/storage/3DQAZPJE/Silva et al. - 2019 - Playing Games in the Dark An approach for cross-m.pdf:application/pdf;arXiv.org Snapshot:/Users/miguelvasco/Zotero/storage/FNH2IIJ3/1911.html:text/html},
 journal = {arXiv:1911.12851 [cs]},
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
 month = {November},
 note = {arXiv: 1911.12851},
 shorttitle = {Playing Games in the Dark},
 title = {Playing Games in the Dark: An approach for cross-modality transfer in reinforcement learning},
 url = {http://arxiv.org/abs/1911.12851},
 urldate = {2020-01-04},
 year = {2019}
}

